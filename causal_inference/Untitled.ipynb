{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>Causal Inference</h6>\n",
    "the first week is about definitions and word problems trying to clear up the terms. \n",
    "<p>Problem statement: we are trying to distinguish between 2 cases if estrogen therapy pts have higher rates of cancer\n",
    "    is this cause and effect, ie does estrogen therapy cause cancer or is this a bias where estrogen therapy leads to bleeding\n",
    "    which leads to exam which leads to more testing for cancer? \n",
    "   </p>\n",
    "<p>\n",
    "<h6>1. Cause and Effect or ascertainment bias?</h6>\n",
    "Example form 70s where women received estrogen therapy after menopause. Noticed higher cancer rate \n",
    "in therapy pts, 2 researchers proposed the data association was not causal but estrogens lead to diagnosis of cancers\n",
    "that was already there!!!. They know 20-60% of cancers are asymptomatic and we only see them if we look for them. Estrogen causes bleeding\n",
    "which they proposed caused looking into cause which revealed cancer. This was not a causation where E caused C. \n",
    "They called this ascertainment bias; the association between estrogen use and cancer because estrogen use led to exam \n",
    "which unveiled cancer. There were 2 possible explantations, one was estrogen causes cancer another was estrogen led to bleeding\n",
    "which led to exam which led to cancer discovery. \n",
    "</p>\n",
    "<h6>2. What is a DAG?</h6>\n",
    "<p>1. <li>Lots of focus on the definiton of terms cause and effect modified by the terms common and shared. A->B: A has direct effect on B,A causes B. </li>\n",
    "      <li>A->B->C; A is common cause of B and C</li> \n",
    "</p>\n",
    "<p>2. Expert knowledge is used to build the graph. If there is no expert knowledge for a edge then we include the \n",
    "edge! Knowledge is represented by the ABSENCE of arrows. A B->C is such a graph. There is insufficuent knowledge \n",
    "if A B causes C so add in arrow. We know A doesnt cause B or C! The normal intuition is the reverse of this convention</p>\n",
    "\n",
    "<p></p>\n",
    "<p>3. An association between 2 variables is both causal model and stat model. stat defin is the porportion\n",
    "is different if there is an association and if there isnt an association. If A->Y where A is smoking and Y is cancer and\n",
    "they are both binary then a smoker has a cancer rate of 10% and a nonsmoker 1%. These proportions are 10x different. </p>\n",
    "<p>\n",
    "A causal graph L->A->Y. L has effet on A and A has effect on Y. If L has an effect on Y not through A then indicate by a direct arrow from \n",
    "L to Y. This is not shown because I cannot draw this in text. L to Y is not mediated through A. Each arrow is a causal effect. No effect no arrow. Definition: if expert knowledge\n",
    "    is unable to exclude possible effect then draw all arrows!! DAG complete if all edges present. If expert knowledge available, \n",
    "    use it to ELIMINATE edges! This is opposite of intuition! A DAG is causal if 2 variables share a cause; this is called a markov condition. \n",
    "    A->B is an example of A and B being shared. \n",
    "</p>\n",
    "<p>The elimination of edges definition on csuasl DAG has some consequences. if we randomly assign a pt using a coin flip \n",
    "whether to take aspirin or not and measure if they got a stroke A->Y where A is assignment to aspirin and Y is stroke do we \n",
    "need to assign other variables like high blood pressure, heart disease to A? No becasue those those affect the assignment\n",
    "of aspirin to A. The randomization is the only effect on A, the coin flip. so the definition of a Causal DAG in a RCT is not based\n",
    "on other factors which we KNOW to cause stroke! However if we take a population and screen if thyey have aspirin and another group which\n",
    "didnt take aspirin then for a causal DAG do we need to include other variables like HBP, coronary heart disease? Yes!!! Because those conditions\n",
    "would affect whether or not they take aspirin!!!!! Very different viewpoints for the definition of a CAUSAL DAG! </p>\n",
    "<img src=\"w12/w12_a.png\">\n",
    "<img src=\"w12/w12_b.png\">\n",
    "<img src=\"w12/w12_c.png\">\n",
    "<img src=\"w12/w12_d.png\">\n",
    "\n",
    "<h6>3. Cause and Effect</h6>\n",
    "<p>\n",
    "There are 2 main concepts, conditional associations and independence. If there is no arrow between 2 variables then \n",
    "they are independent. \n",
    "The simplest DAG; A->Y is a marginal unconditional association between 2 variables. There is no conditional variable. Only 2 variables. A conditional variable\n",
    "would be a 3rd variable. A->B->Y. We can look at the causation of A to Y at different levels of B!  \n",
    "</p>\n",
    "<p>Consider teh DAG where L is binary, smoker or nonsmoker, A is yellow fingers, 0 no yellow fingers, 1 yellow fingers, \n",
    "Y is lung cancer 0 no cancer, 1 has lung cancer. The DAG we draw with expert knowledge is L->A and L->Y but no edge\n",
    "from A->Y. This says smoking/no smoking can lead to yellow fingers and cancer. Yellow fingers cannot lead to cancer, a \n",
    "pt can have yellow fingers and be a painter! The yellow finger and cancer are independent. this is true if L is binary or multi level. If L\n",
    "is multilevel from 0=40 where the number is number of cigarettes they smoke, 40 cigs they have 10% of cancer vs 0 cigs they have 1% cancer; and\n",
    "they have a percentage of yellow fingers, .01% if 0 cigs and 4% if smoker. The .01% if the pt is a painter! </p>\n",
    "<p>Causal DAGS are both causal models and statistical models at same time. A stat model represents associations\n",
    "and independence between variables. We define association between 2 variables if teh data shows a different proportion\n",
    "between 2 different outcomes. If A->Y where A is smoke and Y is lung cancer then we separate into 2 data sets and caluclate \n",
    "percentage of cancer w smoking and wo smoking. If those are different then that is an association. Did not cover how to determine differnt.\n",
    "The link to causal graph is if A->Y is causal then we expect an association. In generatl if A causes Y then we expect there to \n",
    "be a statistical association between the 2 variables else they are independent if no diference. </p>\n",
    "<p>B is a mediator, A->B->Y where there is no direct path from A to Y. A and Y are both conditional on B. If A is a smoker or non smoker and smoking\n",
    "causes DNA damage as indicated by B, and DNA damage causes cancer then smoking doesnt directly cause cancer. </p>\n",
    "<img src=\"w13/w13_a.png\">\n",
    "<img src=\"w13/w13_b.png\">\n",
    "<img src=\"w13/w13_c.png\">\n",
    "\n",
    "<h6>4. Confounding</h6>\n",
    "<p><img src=\"w14/w14lec_a.png\"> The causal model from the expert says A which is yellow fingers does not cause cancer. The expert model says 2 things, first \n",
    "smoking causes yellow fingers as denoted by L->A and smoking causes cancer shown by the L->Y arrow. The expert makes yellow fingers and\n",
    "cancer independent. However when we download data we see there is an association between\n",
    "pts with yellow fingers and those with cancer. The porportion of pts wo yellow fingers and cancer is NOT the same as pts\n",
    "with yellow fingers and cancer. We say there is a bias. This bias is from a confounding variable. The bias is this association causing us to \n",
    "think yellow fingers cause cancer while yellow fingers is caused by smoking which causes cancer. </p>\n",
    "<img src=\"w14/w14_a.png\">\n",
    "<img src=\"w14/w14_b.png\">\n",
    "<img src=\"w14/w14_c.png\">\n",
    "\n",
    "<h6>5. Selection Bias</h6>\n",
    "<img src=\"w15/w15_a.png\"> \n",
    "\n",
    "<p></p>\n",
    "<h6>6. D separation</h6>\n",
    "<p></p>\n",
    "<h6>7. Estrogen adn Cancer worked example</h6>\n",
    "<p></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
