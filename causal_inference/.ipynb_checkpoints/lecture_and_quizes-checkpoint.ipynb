{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h6>Causal Inference</h6>\n",
    "the first week is about definitions and word problems trying to clear up the terms. \n",
    "<p>Problem statement: we are trying to distinguish between 2 cases if estrogen therapy pts have higher rates of cancer\n",
    "    is this cause and effect, ie does estrogen therapy cause cancer or is this a bias where estrogen therapy leads to bleeding\n",
    "    which leads to exam which leads to more testing for cancer? \n",
    "</p>\n",
    "<p>\n",
    "<h6>1. Cause and Effect or ascertainment bias?</h6>\n",
    "Example form 70s where women received estrogen therapy after menopause. Noticed higher cancer rate \n",
    "in therapy pts, 2 researchers proposed the data association was not causal but estrogens lead to diagnosis of cancers\n",
    "that was already there!!!. They know 20-60% of cancers are asymptomatic and we only see them if we look for them. Estrogen causes bleeding\n",
    "which they proposed caused looking into cause which revealed cancer. This was not a causation where E caused C. \n",
    "They called this ascertainment bias; the association between estrogen use and cancer because estrogen use led to exam \n",
    "which unveiled cancer. There were 2 possible explantations, one was estrogen causes cancer another was estrogen led to bleeding\n",
    "which led to exam which led to cancer discovery. \n",
    "</p>\n",
    "<h6>2. What is a DAG?</h6>\n",
    "<p>1. <li>Lots of focus on the definiton of terms cause and effect modified by the terms common and shared. A->B: A has direct effect on B,A causes B. </li>\n",
    "      <li>A->B->C; A is common cause of B and C</li> \n",
    "</p>\n",
    "<p>2. Expert knowledge is used to build the graph. If there is no expert knowledge for a edge then we include the \n",
    "edge! Knowledge is represented by the ABSENCE of arrows. A B->C is such a graph. There is insufficuent knowledge \n",
    "if A B causes C so add in arrow. We know A doesnt cause B or C! The normal intuition is the reverse of this convention</p>\n",
    "\n",
    "<p></p>\n",
    "<p>3. An association between 2 variables is both causal model and stat model. stat defin is the porportion\n",
    "is different if there is an association and if there isnt an association. If A->Y where A is smoking and Y is cancer and\n",
    "they are both binary then a smoker has a cancer rate of 10% and a nonsmoker 1%. These proportions are 10x different. </p>\n",
    "<p>\n",
    "A causal graph L->A->Y. L has effet on A and A has effect on Y. If L has an effect on Y not through A then indicate by a direct arrow from \n",
    "L to Y. This is not shown because I cannot draw this in text. L to Y is not mediated through A. Each arrow is a causal effect. No effect no arrow. Definition: if expert knowledge\n",
    "    is unable to exclude possible effect then draw all arrows!! DAG complete if all edges present. If expert knowledge available, \n",
    "    use it to ELIMINATE edges! This is opposite of intuition! A DAG is causal if 2 variables share a cause; this is called a markov condition. \n",
    "    A->B is an example of A and B being shared. \n",
    "</p>\n",
    "<p>The elimination of edges definition on csuasl DAG has some consequences. if we randomly assign a pt using a coin flip \n",
    "whether to take aspirin or not and measure if they got a stroke A->Y where A is assignment to aspirin and Y is stroke do we \n",
    "need to assign other variables like high blood pressure, heart disease to A? No becasue those those affect the assignment\n",
    "of aspirin to A. The randomization is the only effect on A, the coin flip. so the definition of a Causal DAG in a RCT is not based\n",
    "on other factors which we KNOW to cause stroke! However if we take a population and screen if thyey have aspirin and another group which\n",
    "didnt take aspirin then for a causal DAG do we need to include other variables like HBP, coronary heart disease? Yes!!! Because those conditions\n",
    "would affect whether or not they take aspirin!!!!! Very different viewpoints for the definition of a CAUSAL DAG! </p>\n",
    "<img src=\"w12/w12_a.png\">\n",
    "<img src=\"w12/w12_b.png\">\n",
    "<img src=\"w12/w12_c.png\">\n",
    "<img src=\"w12/w12_d.png\">\n",
    "\n",
    "<h6>3. Cause and Effect</h6>\n",
    "<img src=\"w13/w13a.png\">\n",
    "<p>\n",
    "There are 2 main concepts, Causes and Effects. Confounding is a common cause, Selection Bias is a common effect. \n",
    "\n",
    "</p>\n",
    "<p>Definition: conditional associations and independence. If there is no arrow between 2 variables then \n",
    "they are independent.\n",
    "</p>\n",
    "<p>\n",
    "The simplest DAG; A->Y is a marginal unconditional association between 2 variables. There is no conditional variable. Only 2 variables. A conditional variable\n",
    "would be a 3rd variable. A->B->Y. We can look at the causation of A to Y at different levels of B!  \n",
    "</p>\n",
    "<p>Consider teh DAG where L is binary, smoker or nonsmoker, A is yellow fingers, 0 no yellow fingers, 1 yellow fingers, \n",
    "Y is lung cancer 0 no cancer, 1 has lung cancer. The DAG we draw with expert knowledge is L->A and L->Y but no edge\n",
    "from A->Y. This says smoking/no smoking can lead to yellow fingers and cancer. Yellow fingers cannot lead to cancer, a \n",
    "pt can have yellow fingers and be a painter! The yellow finger and cancer are independent. this is true if L is binary or multi level. If L\n",
    "is multilevel from 0=40 where the number is number of cigarettes they smoke, 40 cigs they have 10% of cancer vs 0 cigs they have 1% cancer; and\n",
    "they have a percentage of yellow fingers, .01% if 0 cigs and 4% if smoker. The .01% if the pt is a painter! \n",
    "</p>\n",
    "<p>Causal DAGS are both causal models and statistical models at same time. A stat model represents associations\n",
    "and independence between variables. We define association between 2 variables if teh data shows a different proportion\n",
    "between 2 different outcomes. If A->Y where A is smoke and Y is lung cancer then we separate into 2 data sets and caluclate \n",
    "percentage of cancer w smoking and wo smoking. If those are different then that is an association. Did not cover how to determine differnt.\n",
    "The link to causal graph is if A->Y is causal then we expect an association. In generatl if A causes Y then we expect there to \n",
    "be a statistical association between the 2 variables else they are independent if no diference. \n",
    "</p>\n",
    "<p>B is a mediator, A->B->Y where there is no direct path from A to Y. A and Y are both conditional on B. If A is a smoker or non smoker and smoking\n",
    "causes DNA damage as indicated by B, and DNA damage causes cancer then smoking doesnt directly cause cancer. \n",
    "</p>\n",
    "<img src=\"w13/w13_a.png\">\n",
    "<img src=\"w13/w13_b.png\">\n",
    "<img src=\"w13/w13_c.png\">\n",
    "\n",
    "<h6>4. Confounding</h6>\n",
    "<p><img src=\"w14/w14lec_a.png\"> \n",
    "Common/Shared Causes. A and Y share a cause as indicated by the shared variable A between Y and L. There are arrows between\n",
    "A and Y and A and L so A is a shared variable. The author uses 2 definitions to refer to the same thing. Interchangable definition common==shared. A is also a shared cause. \n",
    "Might be a unique definition for this author/speaker only. Unclear. The lesson is a common cause or shared cause leads to data association. Bias is the definition of data association.\n",
    "</p>\n",
    "<p>\n",
    "A common cause or shared cause leads to a statistical model with a bias. There is an error in the transcript that makes this \n",
    "particulary difficult to understand in addition to the verbosity. Have to use the find function in transcript text files to find these terms. \n",
    "Very annoying. The key to DAGS is it represents both a causal model based on experts and a statistical model based on data. Sometimes\n",
    "a causal pattern implies a bias. A shared/common cause implies a statistical bias called confounding and you can condition on different levels\n",
    "of the shared variable to reduce effect of confounding. No examples or development of this. \n",
    "</p>\n",
    "<p>\n",
    "Conditioning on common cause A refers to the association between A and Y for different levels of L. \n",
    "</p>\n",
    "<p>\n",
    "To condition on different levels of L look at different groups and see if there is a bias or statistical association. First lets split the patient population into \n",
    "40 groups where L is now divided into the number of cigs each patient smokes with N=0 to 40. First look at the N=0 or nonsmokers. The nonsmokers can have yellow fingers, if one\n",
    "is a painter as an example and it doesnt lead to additional cancer cases. To do this mathematically we look at the proportion of N=0 number of cancer pts and see if this proportion is different \n",
    "whether or not they have yellow fingers or not. Assume the data says there is no effect. Then we know yellow fingers is indepenent of cancer. \n",
    "Do the same for N=40 cigs/day. Data says same thing, split the pts who smoke 40 cigs/day into 2 groups, those w yellow fingers and those wo. Assume the data says\n",
    "teh porportion of those 2 groups is the same and then we can say the yellow finger and cancer variables are statistiaclly independent and there is \n",
    "no association. So we see with this example conditioning on a shared cause has no bias so conditioning REMOVES the bias!!! Holy shit batman. That is really big.  \n",
    "</p>\n",
    "<img src=\"w14/w14_a.png\">\n",
    "<img src=\"w14/w14_b.png\">\n",
    "<img src=\"w14/w14_c.png\">\n",
    "Summary: Common cause implies bias called confounding. Common cause with conditioning on different levels of shared variable removes bias. \n",
    "<h6>5. Selection Bias</h6>\n",
    "<img src=\"w15/w15_a.png\"> \n",
    "<p>\n",
    "Common effects. A and Y have a common effect on L. Common effect does not lead to a data association. Conditioning on the common\n",
    "effect leads to association or bias. This is called selection bias. Selection bias is when you condition on a level. Take as an example all the covid  patients\n",
    "and the statement is recovered covid pts see myocartidal infarction or MI. is there selection bias in this statement? Are the pts who are tested for MI the more severe cases? If so\n",
    "then the statement recovered covid pts have MI is not completely accurate bc it may suffer from selection bias. Here the level in the common effect is the serverity of the covid infection. \n",
    "\n",
    "</p>\n",
    "<p>\n",
    "Y is a binary environmental factor. A is binary a genetic factor. L is a binary lung cancer effect. L is the common\n",
    "effect between L and A.\n",
    "</p>\n",
    "<p>\n",
    "An environmental\n",
    "factor can cause lung cancer, and a genetic factor can cause lung cancer. The expert knows there is no causal effect between \n",
    "A and Y; A cannot cause Y but can the data can show an association between A and Y? No. These are independent. Conditioning on different levls of L\n",
    "leads to an association between A and Y. How? Pick out a group in L, say the group with lung cancer. Looking at this group only, \n",
    "is there \n",
    "</p>\n",
    "<p>\n",
    "L is a collider in the DAG because it collides with 2 nodes. A collider has the opposite effect than other nodes. A collider\n",
    "blocks the flow of association so there is no association for common effect. If conditioned on; there is an association. This is \n",
    "true in general for ALL common effects not just colliders!!!!!!\n",
    "\n",
    "</p>\n",
    "<p>\n",
    "Selection bias exists when we condition on a collider or anyting related to the collider. \n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<img src=\"w15/w5_q1.png\">\n",
    "<img src=\"w15/w5_q2.png\">\n",
    "\n",
    "</p>\n",
    "<h6>6. D separation</h6>\n",
    "<img src=\"w16/w6_lec1.png\">\n",
    "<img src=\"w16/w6_lec2.png\">\n",
    "<img src=\"w16/w6_lec3.png\">\n",
    "<img src=\"w16/w6_lec4.png\">\n",
    "<img src=\"w16/w6_lec5.png\">\n",
    "<img src=\"w16/w6_lec6.png\">\n",
    "<img src=\"w16/w6_lec7.png\">\n",
    "<img src=\"w16/w6_lec8.png\">\n",
    "<img src=\"w16/w6_lec9.png\">\n",
    "<img src=\"w16/w6_lec10.png\">\n",
    "<img src=\"w16/w6_lec11.png\">\n",
    "<img src=\"w16/w6_lec12.png\">\n",
    "\n",
    "\n",
    "<p></p>\n",
    "<h6>7. Estrogen adn Cancer worked example</h6>\n",
    "<p></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
